#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Region Growing Segmentation for CloudCompare Binary PCD + Joint Sets Clustering
-------------------------------------------------------------------------------

è¦ç‚¹ï¼š
- è¾“å…¥ï¼šCloudCompare äºŒè¿›åˆ¶ PCDï¼ˆå«æ³•å‘ï¼‰ï¼›æ›²ç‡åœ¨é¢œè‰² R é€šé“ [0,1]
- åŒºåŸŸç”Ÿé•¿ï¼šä½æ›²ç‡ä½œç§å­ï¼›è·ç¦»+æ³•å‘è§’åº¦+æ›²ç‡ä¸‰é‡åˆ¤å®šï¼›å¤šæ ¸ KDTreeï¼›tqdm è¿›åº¦ï¼›AABB äº¤äº’æ¡†é€‰
- åŒºåŸŸæ³•å‘ï¼šå¯¹æ¯ä¸ªåŒºåŸŸç‚¹åš PCA/SVD å¹³é¢æ‹Ÿåˆå¾—åˆ°æ³•å‘ï¼ˆæ›´ç¨³å¥ï¼‰
- ç»“æ„é¢ç»„åˆ†ç»„ï¼ˆæ–¹å‘è§’ç‰ˆæœ¬ï¼‰ï¼š
    å…ˆå°†åŒºåŸŸæ³•å‘ç»Ÿä¸€åˆ° **y>0 åŠçƒ**ï¼Œç„¶åç”¨**çœŸå®æ–¹å‘è§’ï¼ˆä¸å–ç»å¯¹å€¼ï¼Œ0~180Â°ï¼‰**æ„é€ è·ç¦»çŸ©é˜µåš DBSCAN
- å•åŒºå¤§é¢ç‰‡è§„åˆ™ï¼šè‹¥åŒºåŸŸç‚¹æ•° â‰¥ æ€»ç‚¹æ•°çš„ `major_singleton_percent%`ï¼ˆé»˜è®¤ 1%ï¼‰ï¼Œå³ä½¿ä¸ºå™ªå£°ä¹Ÿå¼ºåˆ¶æˆç‹¬ç«‹ç»„
- â­ æ–°å¢ï¼šåˆ†ç»„æ­¥éª¤**ä¸å†å°†ä»»ä½•å·²æˆåŒºåŸŸåˆ’ä¸ºå™ªå£°**ï¼›DBSCAN äº§ç”Ÿçš„ -1 ä¼šè¢«åˆ†é…åˆ°æœ€è¿‘ç°‡ï¼›è‹¥æ— ç°‡åˆ™å„è‡ªæˆç»„
- å¯¼å‡ºï¼šæ•´ä½“ä¸å„åŒºåŸŸã€labelsã€summaryã€configï¼›æ¯ä¸ªç»“æ„é¢ç»„ä¸æœªåˆ†ç»„ç‚¹äº‘ï¼›å¯é€‰ç­‰é¢ç§¯ææŠ•å½±å›¾
- å¯è§†åŒ–ï¼šæŒ‰åŒºåŸŸä¸Šè‰²ã€æŒ‰ç»“æ„é¢ç»„ä¸Šè‰²

ä¾èµ–ï¼š
    pip install open3d scipy numpy tqdm
    pip install scikit-learn matplotlib
"""
from __future__ import annotations

import argparse
import colorsys
import csv
import datetime as _dt
import json
import math
import os
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from typing import List, Tuple, Optional, Dict

import numpy as np
from tqdm import tqdm

# --------- optional file dialog fallback (when pcd arg omitted) ----------
def askopenfilename_pcd() -> Optional[str]:
    try:
        import tkinter as tk
        from tkinter import filedialog
        root = tk.Tk()
        root.withdraw()
        fp = filedialog.askopenfilename(
            title="é€‰æ‹© CloudCompare å¯¼å‡ºçš„ .pcd æ–‡ä»¶",
            filetypes=[("PCD files", "*.pcd"), ("All files", "*.*")]
        )
        root.destroy()
        return fp if fp else None
    except Exception:
        return None
# ------------------------------------------------------------------------

try:
    import open3d as o3d
except Exception as e:
    raise RuntimeError("Open3D is required. Please `pip install open3d`") from e

try:
    from scipy.spatial import cKDTree
except Exception as e:
    raise RuntimeError("SciPy is required. Please `pip install scipy`") from e

# ç»“æ„é¢ç»„èšç±»ï¼ˆå¯é€‰ï¼‰
try:
    from sklearn.cluster import DBSCAN
except Exception:
    DBSCAN = None  # è‹¥æœªå®‰è£…ï¼Œå°†åœ¨ä½¿ç”¨æ—¶æç¤º


default_workers = -1


@dataclass
class GrowConfig:
    radius: float = 0.2                  # è·ç¦»/é‚»åŸŸåŠå¾„ï¼ˆç±³ï¼‰
    angle_deg: float = 20.0              # æ³•å‘é˜ˆå€¼ï¼ˆåº¦ï¼‰
    curvature_max: float = 0.1           # æ›²ç‡ä¸Šé™ï¼ˆR é€šé“å•ä½ 0..1ï¼‰
    curvature_delta_max: Optional[float] = 0.5  # ä¸ç§å­æ›²ç‡å·®çš„ä¸Šé™ï¼ˆå¯é€‰ï¼‰
    seed_percentile: float = 5.0         # å–æœ€ä½ X% æ›²ç‡ä½œä¸ºç§å­
    min_region_size: int = 100           # æœ€å°åŒºåŸŸç‚¹æ•°
    precompute_neighbors: bool = True    # æ˜¯å¦é¢„è®¡ç®—å…¨éƒ¨é‚»åŸŸ
    neighbor_mem_cap_mb: int = 800       # é‚»åŸŸè¡¨å†…å­˜ä¸Šé™ï¼ˆè¶…è¿‡åˆ™æ”¹ä¸ºæŒ‰éœ€æŸ¥è¯¢ï¼‰
    workers: int = default_workers       # cKDTree å¹¶è¡ŒæŸ¥è¯¢æ ¸å¿ƒæ•°ï¼ˆ<=0 è¡¨ç¤ºæ‰€æœ‰æ ¸å¿ƒï¼‰
    use_region_mean_normal: bool = True  # ç”Ÿé•¿æ—¶ç”¨åŒºåŸŸå¹³å‡æ³•å‘ï¼ˆæ•ˆç‡ä¼˜å…ˆï¼‰
    random_seed: int = 42                # éšæœºç§å­ï¼ˆå¯å¤ç°ï¼‰


# --------------------- Utilities ---------------------
def ensure_dir(p: Path) -> None:
    p.mkdir(parents=True, exist_ok=True)

def now_str() -> str:
    return _dt.datetime.now().strftime("%Y%m%d_%H%M%S")

def normalize_rows(v: np.ndarray) -> np.ndarray:
    n = np.linalg.norm(v, axis=1, keepdims=True) + 1e-12
    return v / n

def angle_to_color(n: np.ndarray) -> Tuple[float, float, float]:
    """æ ¹æ®æ³•å‘æ–¹å‘æ˜ å°„é¢œè‰²ï¼ˆHSVï¼‰"""
    n = n / (np.linalg.norm(n) + 1e-12)
    az = math.atan2(n[1], n[0])                # [-pi, pi]
    el = math.acos(np.clip(n[2], -1.0, 1.0))   # [0, pi]
    hue = (az + math.pi) / (2.0 * math.pi)     # [0,1]
    val = 1.0 - (el / math.pi) * 0.5
    r, g, b = colorsys.hsv_to_rgb(hue, 1.0, val)
    return (r, g, b)

def set_id_to_color(k: int, K: int) -> Tuple[float, float, float]:
    """ç”Ÿæˆç»„é¢œè‰²ï¼ˆHSV å‡åŒ€åˆ†å¸ƒï¼‰ï¼›k=-1 ä½¿ç”¨ç°è‰²"""
    if k < 0 or K <= 0:
        return (0.7, 0.7, 0.7)
    hue = (k % K) / float(K)
    r, g, b = colorsys.hsv_to_rgb(hue, 0.85, 0.95)
    return (r, g, b)

def load_cc_pcd(pcd_path: Path) -> o3d.geometry.PointCloud:
    """è¯»å– CloudCompare äºŒè¿›åˆ¶ PCDï¼Œè¦æ±‚åŒ…å«æ³•å‘å’Œé¢œè‰²ï¼ˆR ä¸ºæ›²ç‡ï¼‰"""
    pcd = o3d.io.read_point_cloud(str(pcd_path))
    if pcd.is_empty():
        raise ValueError(f"Failed to read or empty point cloud: {pcd_path}")
    if not pcd.has_normals():
        raise ValueError("Input PCD must contain normals (nx,ny,nz).")
    if not pcd.has_colors():
        raise ValueError("Input PCD must contain colors; curvature is expected in R channel.")
    return pcd

def interactive_select_aabb(pcd: o3d.geometry.PointCloud, window_name: str = "é€‰æ‹©ä¸¤ä¸ªç‚¹å®šä¹‰ ROI (AABB)") -> Tuple[o3d.geometry.AxisAlignedBoundingBox, np.ndarray]:
    """
    SHIFT + å·¦é”®é€‰æ‹© 2 ä¸ªç‚¹ï¼Œç”Ÿæˆ AABBã€‚è¿”å› (AABB, mask)
    """
    print("\n[ROI] æ“ä½œï¼šåœ¨çª—å£ä¸­æŒ‰ä½ SHIFT + å·¦é”®ï¼Œä¾æ¬¡é€‰æ‹©ä¸¤ä¸ªç‚¹ä½œä¸ºå¯¹è§’ï¼›æŒ‰ Q é€€å‡ºã€‚\n")
    try:
        picked = o3d.visualization.draw_geometries_with_editing([pcd], window_name=window_name)
    except Exception:
        vis = o3d.visualization.VisualizerWithEditing()
        vis.create_window(window_name)
        vis.add_geometry(pcd)
        vis.run()
        vis.destroy_window()
        picked = vis.get_picked_points()

    if len(picked) < 2:
        raise RuntimeError(f"éœ€è¦é€‰æ‹© 2 ä¸ªç‚¹ä½œä¸º AABBï¼Œå¯¹åº”å½“å‰é€‰æ‹©æ•°é‡ï¼š{len(picked)}")

    pts = np.asarray(pcd.points)
    a = pts[picked[0]]
    b = pts[picked[1]]
    lo = np.minimum(a, b)
    hi = np.maximum(a, b)

    aabb = o3d.geometry.AxisAlignedBoundingBox(lo, hi)
    mask = ((pts[:, 0] >= lo[0]) & (pts[:, 0] <= hi[0]) &
            (pts[:, 1] >= lo[1]) & (pts[:, 1] <= hi[1]) &
            (pts[:, 2] >= lo[2]) & (pts[:, 2] <= hi[2]))
    return aabb, mask


# -------------------- Neighbor build --------------------
def build_neighbors(points: np.ndarray, radius: float, workers: int,
                    mem_cap_mb: int, precompute: bool):
    tree = cKDTree(points)
    neighbors: Optional[List[np.ndarray]] = None
    if not precompute:
        return tree, None

    # é‡‡æ ·ä¼°è®¡å¹³å‡é‚»åŸŸè§„æ¨¡ï¼Œåšå†…å­˜é¢„ä¼°
    rng = np.random.default_rng(42)
    N = len(points)
    if N == 0:
        return tree, None
    sample_idx = rng.choice(N, size=min(256, N), replace=False)
    sample_counts = [len(tree.query_ball_point(points[i], r=radius)) for i in sample_idx]
    avg_k = float(np.mean(sample_counts)) if sample_counts else 0.0
    estimated_bytes = N * max(avg_k, 1.0) * 4.0
    estimated_mb = estimated_bytes / (1024 ** 2)

    if estimated_mb > mem_cap_mb:
        print(f"[é‚»åŸŸ] é¢„è®¡é‚»åŸŸå­˜å‚¨ {estimated_mb:.1f} MB > ä¸Šé™ {mem_cap_mb} MBï¼Œæ”¹ä¸ºæŒ‰éœ€æŸ¥è¯¢")
        return tree, None

    print(f"[é‚»åŸŸ] å…¨ä½“é‚»åŸŸå¹¶è¡Œæ„å»ºï¼Œworkers={workers}ï¼Œé¢„è®¡å†…å­˜ ~{estimated_mb:.1f} MB")
    idx_arrays = tree.query_ball_point(points, r=radius, workers=workers)
    neighbors = [np.asarray(ix, dtype=np.int32) for ix in idx_arrays]
    return tree, neighbors


# -------------------- Plane fitting helper --------------------
def fit_plane_normal(pts_region: np.ndarray) -> np.ndarray:
    """
    ç”¨ PCA/SVD å¯¹åŒºåŸŸç‚¹åæ ‡æ‹Ÿåˆå¹³é¢ï¼Œå–æœ€å°ç‰¹å¾å€¼å¯¹åº”ç‰¹å¾å‘é‡ä¸ºæ³•å‘ï¼ˆå•ä½å‘é‡ï¼‰ã€‚
    æœ¬ç‰ˆå°†æ–¹å‘ç»Ÿä¸€åˆ° y>0 åŠçƒï¼›è‹¥ yâ‰ˆ0ï¼Œä½¿ç”¨ z<0 ä½œä¸ºå¹³å±€è§„åˆ™å°†å…¶ç¿»åˆ°â€œä¸Šæ–¹â€ã€‚
    """
    n = pts_region.shape[0]
    if n < 3:
        return np.array([0.0, 0.0, 1.0], dtype=np.float64)

    c = pts_region.mean(axis=0)
    X = pts_region - c
    C = X.T @ X
    try:
        w, v = np.linalg.eigh(C)
        idx_min = int(np.argmin(w))
        nvec = v[:, idx_min]
        nvec = nvec / (np.linalg.norm(nvec) + 1e-12)

        # ç»Ÿä¸€åˆ° y>0 åŠçƒï¼›è‹¥ yâ‰ˆ0 ç”¨ z ä½œä¸ºå¹³å±€è§„åˆ™
        eps = 1e-12
        if (nvec[1] < 0.0) or (abs(nvec[1]) <= eps and nvec[2] < 0.0):
            nvec = -nvec

        return nvec.astype(np.float64)
    except Exception:
        return np.array([0.0, 0.0, 1.0], dtype=np.float64)


# -------------------- Region Growing --------------------
def region_growing(points: np.ndarray,
                   normals: np.ndarray,
                   curvature: np.ndarray,
                   cfg: GrowConfig,
                   tree: cKDTree,
                   neighbors: Optional[List[np.ndarray]] = None) -> Tuple[np.ndarray, int, np.ndarray]:
    """
    è¿”å›ï¼š
      labels: [N] int32ï¼ŒåŒºåŸŸç¼–å·ï¼›-1 è¡¨ç¤ºæœªæ ‡è®°/å™ªå£°
      num_regions: åŒºåŸŸæ•°
      region_mean_normals: [num_regions, 3] åŒºåŸŸæ³•å‘ï¼ˆPCA å¹³é¢æ‹Ÿåˆï¼Œç»Ÿä¸€åˆ° y>0 åŠçƒï¼‰
    """
    N = len(points)
    labels = np.full(N, -1, dtype=np.int32)
    visited = np.zeros(N, dtype=bool)
    angle_thr = math.radians(cfg.angle_deg)

    # ç§å­ï¼šæœ€ä½æ›²ç‡ç™¾åˆ†ä½
    thresh_seed = np.percentile(curvature, cfg.seed_percentile)
    seed_idx = np.where(curvature <= thresh_seed)[0]
    seed_idx = seed_idx[np.argsort(curvature[seed_idx])]  # ä½æ›²ç‡ä¼˜å…ˆ

    region_id = 0
    region_normals: List[np.ndarray] = []

    pbar = tqdm(total=len(seed_idx), desc="åŒºåŸŸç”Ÿé•¿ï¼ˆç§å­ï¼‰", unit="seed")
    for s in seed_idx:
        pbar.update(1)
        if visited[s]:
            continue

        labels[s] = region_id
        visited[s] = True
        q = [s]
        members = [s]
        norm_sum = normals[s].astype(np.float64).copy()
        seed_curv = curvature[s]
        size = 1

        while q:
            i = q.pop()
            # å€™é€‰é‚»åŸŸ
            if neighbors is not None:
                neigh = neighbors[i]
            else:
                neigh = np.asarray(tree.query_ball_point(points[i], r=cfg.radius), dtype=np.int32)
            if neigh.size == 0:
                continue

            # å»é™¤å·²è®¿é—®
            neigh = neigh[~visited[neigh]]
            if neigh.size == 0:
                continue

            # æ›²ç‡åˆ¤æ®
            mask_curv = curvature[neigh] <= cfg.curvature_max
            if cfg.curvature_delta_max is not None:
                mask_curv &= np.abs(curvature[neigh] - seed_curv) <= cfg.curvature_delta_max
            if not np.any(mask_curv):
                continue
            cand = neigh[mask_curv]

            # æ³•å‘å¤¹è§’åˆ¤æ®ï¼ˆç”¨å½“å‰åŒºåŸŸå¹³å‡æ³•å‘ï¼‰
            if cfg.use_region_mean_normal and size > 0:
                mean_n = norm_sum / (np.linalg.norm(norm_sum) + 1e-12)
            else:
                mean_n = normals[s]
            dots = np.einsum('ij,j->i', normals[cand], mean_n)
            dots = np.clip(dots, -1.0, 1.0)
            ang = np.arccos(dots)
            cand = cand[ang <= angle_thr]
            if cand.size == 0:
                continue

            # æ¥å—å¹¶å…¥é˜Ÿ
            labels[cand] = region_id
            visited[cand] = True
            q.extend(cand.tolist())
            members.extend(cand.tolist())
            norm_sum += normals[cand].sum(axis=0)
            size += cand.size

        # è¿‡å°åŒºåŸŸå‰”é™¤ï¼ˆä½œä¸ºå™ªå£°ï¼‰
        if size < cfg.min_region_size:
            labels[labels == region_id] = -1
            continue

        # ç”¨ PCA å¹³é¢æ‹Ÿåˆå¾—åˆ°åŒºåŸŸæ³•å‘ï¼ˆç»Ÿä¸€åˆ° y>0 åŠçƒï¼‰
        pts_region = points[np.asarray(members, dtype=np.int32)]
        nvec = fit_plane_normal(pts_region)
        region_normals.append(nvec)

        region_id += 1
    pbar.close()

    num_regions = region_id
    if num_regions == 0:
        return labels, 0, np.zeros((0, 3), dtype=np.float64)
    region_mean_normals = np.vstack(region_normals)
    return labels, num_regions, region_mean_normals


# -------------------- Region Stats --------------------
def compute_region_stats(points: np.ndarray, labels: np.ndarray, num_regions: int) -> Tuple[np.ndarray, np.ndarray]:
    """è¿”å› (region_sizes [R], region_centroids [R,3])"""
    valid = labels >= 0
    region_sizes = np.bincount(labels[valid], minlength=num_regions).astype(np.int64)
    sums = np.zeros((num_regions, 3), dtype=np.float64)
    np.add.at(sums, labels[valid], points[valid])
    with np.errstate(invalid='ignore', divide='ignore'):
        centroids = sums / region_sizes[:, None]
    centroids[~np.isfinite(centroids)] = 0.0
    return region_sizes, centroids


# -------------------- Joint Sets Clustering (+ promotion & de-noise) --------------------
def normal_to_geology(n: np.ndarray) -> Tuple[float, float, float]:
    """n å·²å½’ä¸€ï¼›è¿”å› (dip, dipdir, strike) in degreesï¼ˆä½¿ç”¨ z ä½œä¸ºå€¾è§’å‚è€ƒï¼‰"""
    nz = abs(n[2])
    dip = math.degrees(math.acos(np.clip(nz, -1.0, 1.0)))  # 0..90
    dipdir = (math.degrees(math.atan2(n[1], n[0])) + 360.0) % 360.0
    strike = (dipdir - 90.0) % 360.0
    return dip, dipdir, strike

def estimate_kappa(Rbar: float) -> float:
    """Fisher æ¨¡å‹é›†ä¸­åº¦ Îº çš„å¸¸ç”¨è¿‘ä¼¼"""
    Rbar = float(np.clip(Rbar, 0.0, 0.999999))
    if Rbar < 1e-6:
        return 0.0
    return (Rbar * (3.0 - Rbar**2)) / (1.0 - Rbar**2 + 1e-12)

def cluster_joint_sets(region_mean_normals: np.ndarray,
                       region_weights: np.ndarray,
                       total_points: int,
                       eps_deg: float = 5.0,
                       min_samples: int = 3,
                       major_singleton_percent: float = 1.0):
    """
    æŒ‰â€œæœ‰å‘æ³•å‘â€èšç±»ï¼ˆ0~180Â°ï¼‰ï¼š
      å…ˆæŠŠæ³•å‘ç»Ÿä¸€åˆ° y>0 åŠçƒï¼ˆè‹¥ yâ‰ˆ0ï¼Œç”¨ z ä½œä¸ºå¹³å±€è§„åˆ™ï¼‰ï¼Œå†ç”¨æ–¹å‘è§’ arccos(nÂ·m) æ„é€ è·ç¦»çŸ©é˜µã€‚
    åˆ†ç»„åï¼š
      - åº”ç”¨â€œå•åŒºå¤§é¢ç‰‡â€æå‡ï¼›
      - â­ ç¡®ä¿ä¸äº§ç”Ÿåˆ†ç»„å™ªå£°ï¼šæ‰€æœ‰åŒºåŸŸéƒ½ä¼šè¢«åˆ†åˆ°æŸä¸ª setï¼ˆæ—  -1ï¼‰ã€‚
    """
    if DBSCAN is None:
        raise RuntimeError("éœ€è¦ scikit-learn æ‰èƒ½è¿›è¡Œç»“æ„é¢ç»„èšç±»ï¼Œè¯·å…ˆ `pip install scikit-learn`")

    R = region_mean_normals.shape[0]
    if R == 0:
        return np.zeros((0,), dtype=int), 0, np.zeros((0, 3)), np.zeros((0,)), np.zeros((0,), dtype=int), np.zeros((0,))

    # ç»Ÿä¸€åˆ° y>0 åŠçƒå¹¶å•ä½åŒ–ï¼ˆä¸æ‹Ÿåˆé˜¶æ®µä¸€è‡´ï¼‰
    n = region_mean_normals.copy()
    n = normalize_rows(n)
    eps = 1e-12
    flip_mask = (n[:, 1] < 0.0) | ((np.abs(n[:, 1]) <= eps) & (n[:, 2] < 0.0))
    n[flip_mask] *= -1.0

    # æ–¹å‘è§’è·ç¦»çŸ©é˜µï¼ˆä¸å–ç»å¯¹å€¼ï¼‰ï¼šD âˆˆ [0, Ï€]
    dots = np.clip(n @ n.T, -1.0, 1.0)
    D = np.arccos(dots)

    if R > 8000:
        print(f"[è­¦å‘Š] åŒºåŸŸæ•° R={R} å¾ˆå¤§ï¼Œè§’åº¦è·ç¦»çŸ©é˜µä¸º {R}x{R} å¯èƒ½å ç”¨è¾ƒå¤šå†…å­˜ã€‚")

    eps_rad = math.radians(eps_deg)
    clu = DBSCAN(eps=eps_rad, min_samples=int(min_samples), metric="precomputed")
    raw_labels = clu.fit_predict(D)

    # åˆæ­¥æ˜ å°„ï¼šè¿ç»­æ­£æ ‡ç­¾ï¼Œå™ªå£°ä¸º -1
    uniq = [c for c in np.unique(raw_labels) if c >= 0]
    mapping = {c: i for i, c in enumerate(sorted(uniq))}
    set_labels_regions = np.array([mapping.get(c, -1) for c in raw_labels], dtype=int)

    # ------ å•åŒºå¤§é¢ç‰‡â€œå¼ºåˆ¶æˆç»„â€ ------
    if major_singleton_percent > 0.0 and total_points > 0:
        threshold = (major_singleton_percent / 100.0) * float(total_points)
        noise_idx = np.where(set_labels_regions < 0)[0]
        promote_idx = [rid for rid in noise_idx if float(region_weights[rid]) >= threshold]
        if promote_idx:
            next_id = (max(set_labels_regions) + 1) if np.any(set_labels_regions >= 0) else 0
            for rid in promote_idx:
                set_labels_regions[rid] = next_id
                next_id += 1

    # ------ â­ å–æ¶ˆåˆ†ç»„å™ªå£°ï¼šæŠŠå‰©ä½™ -1 å…¨éƒ¨å½’å…¥æŸä¸ªç»„ ------
    if np.any(set_labels_regions < 0):
        neg_idx = np.where(set_labels_regions < 0)[0]

        if np.any(set_labels_regions >= 0):
            # å…ˆç”¨å½“å‰æ­£æ ‡ç­¾ä¼°è®¡å„ç°‡çš„åŠ æƒå‡å€¼æ–¹å‘
            uniq_pos = sorted([c for c in np.unique(set_labels_regions) if c >= 0])
            K_pos = len(uniq_pos)
            means = np.zeros((K_pos, 3), dtype=np.float64)
            for i, k in enumerate(uniq_pos):
                idx = np.where(set_labels_regions == k)[0]
                w = region_weights[idx].astype(np.float64)
                vec = (n[idx] * w[:, None]).sum(axis=0)
                L = np.linalg.norm(vec)
                means[i] = vec / (L + 1e-12)

            # æŠŠæ¯ä¸ª -1 æŒ‡æ´¾åˆ°â€œæ–¹å‘è§’æœ€è¿‘â€çš„å·²æœ‰ç°‡ï¼ˆä¸è®¾é˜ˆå€¼ï¼Œç¡®ä¿æ—  -1ï¼‰
            dm = np.clip(n[neg_idx] @ means.T, -1.0, 1.0)   # ä½™å¼¦ç›¸ä¼¼åº¦
            nearest = np.argmax(dm, axis=1)                 # æœ€å¤§ä½™å¼¦ => æœ€å°è§’
            nearest_sets = np.array([uniq_pos[j] for j in nearest], dtype=int)
            set_labels_regions[neg_idx] = nearest_sets
        else:
            # æ²¡æœ‰ä»»ä½•æ­£æ ‡ç­¾ï¼šæ¯ä¸ªåŒºåŸŸå•ç‹¬æˆç»„ï¼ˆä¸ç•™ -1ï¼‰
            set_labels_regions = np.arange(R, dtype=int)

    # ------ é‡æ–°è¿ç»­åŒ–å¹¶ç»Ÿè®¡ ------
    uniq_final = [c for c in np.unique(set_labels_regions) if c >= 0]
    mapping2 = {c: i for i, c in enumerate(sorted(uniq_final))}
    set_labels_regions = np.array([mapping2.get(c, -1) for c in set_labels_regions], dtype=int)
    K = len(uniq_final)

    set_mean_normals = np.zeros((K, 3), dtype=np.float64)
    set_kappa = np.zeros((K,), dtype=np.float64)
    set_sizes = np.zeros((K,), dtype=int)
    set_weights = np.zeros((K,), dtype=np.float64)

    for k in range(K):
        idx = np.where(set_labels_regions == k)[0]
        set_sizes[k] = idx.size
        w = region_weights[idx].astype(np.float64)
        set_weights[k] = float(w.sum())
        vec = (n[idx] * w[:, None]).sum(axis=0)
        L = np.linalg.norm(vec)
        m = vec / L if L > 0 else np.array([0.0, 0.0, 1.0])
        set_mean_normals[k] = m
        Rbar = L / (w.sum() + 1e-12)
        set_kappa[k] = estimate_kappa(Rbar)

    return set_labels_regions, K, set_mean_normals, set_kappa, set_sizes, set_weights


# -------------------- Coloring --------------------
def colorize_by_region_normal(labels: np.ndarray,
                              region_mean_normals: np.ndarray) -> np.ndarray:
    N = labels.shape[0]
    colors = np.zeros((N, 3), dtype=np.float32)
    for rid in range(region_mean_normals.shape[0]):
        col = np.array(angle_to_color(region_mean_normals[rid]), dtype=np.float32)
        colors[labels == rid] = col
    colors[labels < 0] = np.array([0.7, 0.7, 0.7], dtype=np.float32)
    return colors

def colorize_by_set_id(point_region_labels: np.ndarray,
                       set_labels_regions: np.ndarray,
                       num_sets: int) -> np.ndarray:
    """å°†æ¯ä¸ªç‚¹æ˜ å°„åˆ° set_id å¹¶ä¸Šè‰²ï¼›æœªå½’ç±»ä¸ºç°è‰²"""
    N = point_region_labels.shape[0]
    colors = np.zeros((N, 3), dtype=np.float32)
    colors[:] = np.array([0.7, 0.7, 0.7], dtype=np.float32)
    if set_labels_regions.size == 0:
        return colors
    valid = point_region_labels >= 0
    rid_for_points = point_region_labels[valid]
    set_for_points = set_labels_regions[rid_for_points]
    for k in range(num_sets):
        col = np.array(set_id_to_color(k, num_sets), dtype=np.float32)
        mask = np.zeros_like(valid)
        mask[valid] = (set_for_points == k)
        colors[mask] = col
    return colors


# -------------------- Saving (regions) --------------------
def save_region_outputs(base_dir: Path, base_name: str,
                        pcd_roi: o3d.geometry.PointCloud,
                        labels: np.ndarray,
                        region_mean_normals: np.ndarray,
                        cfg: GrowConfig) -> Dict[str, str]:
    out_dir = base_dir / f"{base_name}_segments_{now_str()}"
    ensure_dir(out_dir)

    pts = np.asarray(pcd_roi.points)
    nrms = np.asarray(pcd_roi.normals)
    colors = colorize_by_region_normal(labels, region_mean_normals)

    pcd_colored = o3d.geometry.PointCloud()
    pcd_colored.points = o3d.utility.Vector3dVector(pts)
    pcd_colored.normals = o3d.utility.Vector3dVector(nrms)
    pcd_colored.colors = o3d.utility.Vector3dVector(colors)

    artifacts: Dict[str, str] = {}
    fused_path = out_dir / f"{base_name}_segmented_colored.ply"
    o3d.io.write_point_cloud(str(fused_path), pcd_colored, write_ascii=False, print_progress=True)
    artifacts["colored_segmentation"] = str(fused_path)

    labels_path = out_dir / f"{base_name}_labels.npy"
    np.save(labels_path, labels)
    artifacts["labels_npy"] = str(labels_path)

    # summary
    num_regions = region_mean_normals.shape[0]
    summary_rows = []
    for rid in range(num_regions):
        k = int(np.sum(labels == rid))
        n = region_mean_normals[rid] if num_regions > 0 else np.array([0, 0, 0])
        summary_rows.append({"region_id": rid, "size": k, "mean_nx": float(n[0]), "mean_ny": float(n[1]), "mean_nz": float(n[2])})
    summary_path = out_dir / f"{base_name}_summary.csv"
    with open(summary_path, "w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=["region_id", "size", "mean_nx", "mean_ny", "mean_nz"])
        w.writeheader()
        w.writerows(summary_rows)
    artifacts["summary_csv"] = str(summary_path)

    cfg_path = out_dir / f"{base_name}_config.json"
    with open(cfg_path, "w", encoding="utf-8") as f:
        json.dump(cfg.__dict__, f, indent=2, ensure_ascii=False)
    artifacts["config_json"] = str(cfg_path)

    artifacts["out_dir"] = str(out_dir)

    # å„åŒºåŸŸå¹¶è¡Œå¯¼å‡º
    region_dir = out_dir / "regions"
    ensure_dir(region_dir)

    def save_one_region(rid: int) -> Tuple[int, str]:
        idx = np.where(labels == rid)[0]
        if idx.size < cfg.min_region_size:
            return rid, ""
        sub = o3d.geometry.PointCloud()
        sub.points = o3d.utility.Vector3dVector(pts[idx])
        sub.normals = o3d.utility.Vector3dVector(nrms[idx])
        sub.colors = o3d.utility.Vector3dVector(colors[idx])
        p = region_dir / f"region_{rid:04d}_n{idx.size}.ply"
        o3d.io.write_point_cloud(str(p), sub, write_ascii=False)
        return rid, str(p)

    print("[ä¿å­˜] æŒ‰åŒºåŸŸå¯¼å‡ºç‚¹äº‘ ...")
    futures = []
    with ThreadPoolExecutor(max_workers=max(os.cpu_count() or 4, 4)) as ex:
        for rid in range(num_regions):
            futures.append(ex.submit(save_one_region, rid))
        for _ in tqdm(as_completed(futures), total=len(futures), unit="region"):
            pass

    return artifacts


# -------------------- Saving (joint sets, per-group & ungrouped) --------------------
def save_joint_sets(out_dir: Path,
                    base_name: str,
                    points: np.ndarray,
                    normals: np.ndarray,
                    region_labels_points: np.ndarray,
                    region_sizes: np.ndarray,
                    set_labels_regions: np.ndarray,
                    set_mean_normals: np.ndarray,
                    set_kappa: np.ndarray) -> Dict[str, str]:
    """
    å¯¼å‡ºï¼š
      - face_to_set.csvï¼ˆåŒºåŸŸâ†’ç»„æ˜ å°„ï¼Œå«åŒºåŸŸå¤§å°ï¼‰
      - joint_sets.csvï¼ˆæ¯ç»„ç»Ÿè®¡ï¼ŒåŒ…æ‹¬ dip/dipdir/strike/Îºï¼‰
      - sets_colored.plyï¼ˆæ•´ä½“æŒ‰ç»“æ„é¢ç»„ä¸Šè‰²ï¼‰
      - sets/ ç›®å½•ï¼šæ¯ä¸ªç»“æ„é¢ç»„ä¸€ä¸ª plyï¼ˆset_XXXX_n*.plyï¼‰
      - sets/set_-1_n*.plyï¼šæœªåˆ†ç»„ç‚¹äº‘ï¼ˆå­˜åœ¨æ‰å¯¼å‡ºï¼‰
    """
    artifacts: Dict[str, str] = {}

    # region -> set æ˜ å°„è¡¨
    R = set_labels_regions.shape[0]
    face_map_rows = []
    for rid in range(R):
        face_map_rows.append({"region_id": rid, "set_id": int(set_labels_regions[rid]), "region_size": int(region_sizes[rid])})
    face_map_path = out_dir / f"{base_name}_face_to_set.csv"
    with open(face_map_path, "w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=["region_id", "set_id", "region_size"])
        w.writeheader()
        w.writerows(face_map_rows)
    artifacts["face_to_set_csv"] = str(face_map_path)

    # ç»„ç»Ÿè®¡
    K = set_mean_normals.shape[0]
    set_rows = []

    # ç‚¹çº§åˆ«çš„ set_idï¼ˆ-1 è¡¨ç¤ºæœªåˆ†ç»„æˆ–æœªå½’å±åŒºåŸŸï¼‰
    point_set = np.full(points.shape[0], -1, dtype=int)
    valid = region_labels_points >= 0
    if R > 0:
        point_set[valid] = set_labels_regions[region_labels_points[valid]]
    set_point_counts = np.bincount(point_set[point_set >= 0], minlength=K).astype(int)

    for k in range(K):
        n = set_mean_normals[k]
        dip, dipdir, strike = normal_to_geology(n)
        set_rows.append({
            "set_id": k,
            "num_regions": int(np.sum(set_labels_regions == k)),
            "num_points": int(set_point_counts[k]),
            "mean_nx": float(n[0]),
            "mean_ny": float(n[1]),
            "mean_nz": float(n[2]),
            "dip": float(dip),
            "dipdir": float(dipdir),
            "strike": float(strike),
            "kappa": float(set_kappa[k]),
        })
    sets_csv = out_dir / f"{base_name}_joint_sets.csv"
    with open(sets_csv, "w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=["set_id","num_regions","num_points","mean_nx","mean_ny","mean_nz","dip","dipdir","strike","kappa"])
        w.writeheader()
        w.writerows(set_rows)
    artifacts["joint_sets_csv"] = str(sets_csv)

    # æ•´ä½“æŒ‰ç»„ç€è‰²
    colors = colorize_by_set_id(region_labels_points, set_labels_regions, K)
    pcd_sets = o3d.geometry.PointCloud()
    pcd_sets.points = o3d.utility.Vector3dVector(points)
    pcd_sets.normals = o3d.utility.Vector3dVector(normals)
    pcd_sets.colors = o3d.utility.Vector3dVector(colors)
    fused_path = out_dir / f"{base_name}_sets_colored.ply"
    o3d.io.write_point_cloud(str(fused_path), pcd_sets, write_ascii=False, print_progress=True)
    artifacts["sets_colored_ply"] = str(fused_path)

    # æ¯ç»„ä¸æœªåˆ†ç»„ï¼šå…¨éƒ¨å¯¼å‡º
    sets_dir = out_dir / "sets"
    ensure_dir(sets_dir)
    print("[ä¿å­˜] æŒ‰ç»“æ„é¢ç»„ï¼ˆå«æœªåˆ†ç»„ï¼‰å¯¼å‡ºç‚¹äº‘ ...")

    def save_one_set_generic(k: int) -> Tuple[int, str]:
        if k >= 0:
            idx = np.where(point_set == k)[0]
        else:
            idx = np.where(point_set < 0)[0]   # æœªåˆ†ç»„ï¼ˆ-1 æˆ–æ— åŒºåŸŸï¼‰
        if idx.size == 0:
            return k, ""
        sub = o3d.geometry.PointCloud()
        sub.points = o3d.utility.Vector3dVector(points[idx])
        sub.normals = o3d.utility.Vector3dVector(normals[idx])
        col = np.array(set_id_to_color(k, max(K, 1)), dtype=np.float32)
        sub.colors = o3d.utility.Vector3dVector(np.tile(col, (idx.size, 1)))
        name = f"set_{k:04d}_n{idx.size}.ply" if k >= 0 else f"set_-1_n{idx.size}.ply"
        p = sets_dir / name
        o3d.io.write_point_cloud(str(p), sub, write_ascii=False)
        return k, str(p)

    futures = []
    with ThreadPoolExecutor(max_workers=max(os.cpu_count() or 4, 4)) as ex:
        futures.append(ex.submit(save_one_set_generic, -1))  # æœªåˆ†ç»„
        for k in range(K):
            futures.append(ex.submit(save_one_set_generic, k))
        for _ in tqdm(as_completed(futures), total=len(futures), unit="set"):
            pass

    artifacts["sets_dir"] = str(sets_dir)
    return artifacts


# -------------------- Stereonet plot --------------------
def plot_stereonet_equal_area(out_dir: Path,
                              base_name: str,
                              region_mean_normals: np.ndarray,
                              set_labels_regions: np.ndarray) -> Optional[str]:
    """
    ç»˜åˆ¶ç­‰é¢ç§¯ææŠ•å½±ï¼ˆLambertï¼‰ï¼šæç‚¹=åŒºåŸŸå¹³å‡æ³•å‘ã€‚
    è¿™é‡Œä»ç»Ÿä¸€åˆ° z>=0 æ¥åšå±•ç¤ºï¼ˆè¡Œä¸šä¹ æƒ¯ä¸ºä¸‹åŠ/ä¸ŠåŠçƒæŠ•å½±ï¼‰ï¼Œä¸å½±å“åˆ†ç»„é€»è¾‘ã€‚
    """
    try:
        import matplotlib.pyplot as plt
    except Exception:
        print("[æç¤º] æœªå®‰è£… matplotlibï¼Œè·³è¿‡ææŠ•å½±å›¾ç»˜åˆ¶ã€‚è¯· `pip install matplotlib`")
        return None

    if region_mean_normals.size == 0:
        return None

    n = region_mean_normals.copy()
    n[n[:, 2] < 0] *= -1.0  # ä»…ç”¨äºå±•ç¤º
    n = normalize_rows(n)
    # Lambert ç­‰é¢ç§¯æŠ•å½±ï¼šr = sqrt(2) * sin(theta/2)ï¼Œtheta = arccos(nz)
    theta = np.arccos(np.clip(n[:, 2], -1.0, 1.0))
    r = np.sqrt(2.0) * np.sin(theta / 2.0)
    # åœ¨æ°´å¹³é¢ä¸Šçš„æ–¹å‘
    xy_norm = np.linalg.norm(n[:, :2], axis=1) + 1e-12
    x = r * (n[:, 0] / xy_norm)
    y = r * (n[:, 1] / xy_norm)

    labels = set_labels_regions
    K = int(np.max(labels)) + 1 if labels.size and np.max(labels) >= 0 else 0
    colors = np.array([set_id_to_color(k, max(K, 1)) for k in range(max(K, 1))])

    plt.figure(figsize=(6, 6))
    ax = plt.gca()
    ax.set_aspect('equal', adjustable='box')
    circle = plt.Circle((0, 0), np.sqrt(2.0), fill=False)
    ax.add_artist(circle)
    if K == 0:
        plt.scatter(x, y, s=8)
    else:
        for k in range(K):
            idx = (labels == k)
            if np.any(idx):
                plt.scatter(x[idx], y[idx], s=10, label=f"Set {k}", c=[colors[k]])
    plt.title("Equal-Area Stereonet (Poles of Regions)")
    if K > 0:
        plt.legend(loc="upper right", fontsize=8)
    plt.xlabel("X"); plt.ylabel("Y")
    out_png = out_dir / f"{base_name}_stereonet.png"
    plt.savefig(out_png, dpi=180, bbox_inches="tight")
    plt.close()
    return str(out_png)


# -------------------- CLI --------------------
def build_argparser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(description="Region Growing + Joint Sets for CloudCompare Binary PCD")
    # è®© pcd å¯é€‰ï¼›ç¼ºçœæ—¶å¼¹æ–‡ä»¶é€‰æ‹©å¯¹è¯æ¡†
    p.add_argument("pcd", type=str, nargs="?", help="Input CloudCompare binary PCD path")
    p.add_argument("--select", action="store_true", help="Interactive ROI: pick 2 points to form an AABB")
    # åŒºåŸŸç”Ÿé•¿å‚æ•°
    p.add_argument("--radius", type=float, default=0.2, help="Neighborhood radius / distance threshold (meters)")
    p.add_argument("--angle-deg", type=float, default=20.0, help="Normal angle threshold (degrees)")
    p.add_argument("--curv-max", type=float, default=0.1, help="Curvature absolute threshold (R channel units 0..1)")
    p.add_argument("--curv-delta", type=float, default=0.5, help="Optional |curvature - curvature_seed| <= delta")
    p.add_argument("--seed-percentile", type=float, default=5.0, help="Seeds from lowest X%% curvature")
    p.add_argument("--min-region-size", type=int, default=100, help="Discard regions smaller than this")
    p.add_argument("--no-precompute", action="store_true", help="Disable neighbor precomputation to save memory")
    p.add_argument("--neighbor-mem-cap", type=int, default=800, help="Neighbor list memory cap in MB")
    p.add_argument("--workers", type=int, default=default_workers, help="cKDTree workers (<=0 means all cores)")
    p.add_argument("--show", action="store_true", help="Show colored segmentation by region normals")

    # ç»“æ„é¢ç»„èšç±»å‚æ•°ï¼ˆæ–¹å‘è§’ç‰ˆæœ¬ï¼‰
    p.add_argument("--no-cluster-sets", action="store_true", help="Disable joint sets clustering")
    p.add_argument("--sets-eps-deg", type=float, default=5.0, help="DBSCAN eps in degrees on directional angle (0~180Â°)")
    p.add_argument("--sets-min-samples", type=int, default=3, help="DBSCAN min_samples (min regions per set)")
    p.add_argument("--major-singleton-percent", type=float, default=1.0,
                   help="Promote a single region to its own set if its point count â‰¥ this percent of total ROI points (0 disables).")
    p.add_argument("--show-sets", action="store_true", help="Show colored segmentation by joint sets")
    p.add_argument("--plot-stereonet", action="store_true", help="Plot equal-area stereonet (requires matplotlib)")
    # å…¼å®¹æ—§å‚æ•°ï¼ˆä¸å†éœ€è¦ï¼›ä¿ç•™ä¸æŠ¥é”™ï¼‰
    p.add_argument("--export-sets", action="store_true", help="(Deprecated) Sets are always exported now.")
    return p


def main():
    parser = build_argparser()
    args = parser.parse_args()

    # å…¼å®¹ï¼šæœªæä¾› pcd è·¯å¾„åˆ™å¼¹å‡ºæ–‡ä»¶é€‰æ‹©å¯¹è¯æ¡†
    if not args.pcd:
        print("[è¾“å…¥] æœªæä¾› pcd å‚æ•°ï¼Œå°†å¼¹å‡ºæ–‡ä»¶é€‰æ‹©å™¨ ...")
        chosen = askopenfilename_pcd()
        if not chosen:
            parser.error("æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶ï¼›è¯·æä¾› pcd è·¯å¾„æˆ–åœ¨å¯¹è¯æ¡†ä¸­é€‰æ‹©ã€‚")
        args.pcd = chosen

    in_path = Path(args.pcd).expanduser().resolve()
    if not in_path.exists():
        parser.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨ï¼š{in_path}")

    print(f"[è¾“å…¥] {in_path}")
    pcd = load_cc_pcd(in_path)

    points_all = np.asarray(pcd.points)
    normals_all = np.asarray(pcd.normals)
    colors_all = np.asarray(pcd.colors)  # [0,1]
    curvature_all = colors_all[:, 0].copy()  # R é€šé“

    # ROI
    if args.select:
        aabb, mask = interactive_select_aabb(pcd)
        print(f"[ROI] AABB min={aabb.get_min_bound()}, max={aabb.get_max_bound()}")
    else:
        print("[ROI] æœªå¯ç”¨äº¤äº’é€‰æ‹©ï¼ˆ--selectï¼‰ï¼Œä½¿ç”¨å…¨é‡ç‚¹")
        mask = np.ones(len(points_all), dtype=bool)

    points = points_all[mask]
    normals = normals_all[mask]
    curvature = curvature_all[mask]

    if points.shape[0] == 0:
        raise RuntimeError("ROI å†…æ— ç‚¹ï¼Œæ— æ³•åˆ†å‰²")

    # é…ç½®
    cfg = GrowConfig(
        radius=float(args.radius),
        angle_deg=float(args.angle_deg),
        curvature_max=float(args.curv_max),
        curvature_delta_max=(float(args.curv_delta) if args.curv_delta is not None else None),
        seed_percentile=float(args.seed_percentile),
        min_region_size=int(args.min_region_size),
        precompute_neighbors=not args.no_precompute,
        neighbor_mem_cap_mb=int(args.neighbor_mem_cap),
        workers=int(args.workers),
    )

    # é˜¶æ®µ 1ï¼šé‚»åŸŸ
    print("[é˜¶æ®µ] 1/5 é‚»åŸŸæ„å»º")
    tree, neighbors = build_neighbors(points, cfg.radius, cfg.workers, cfg.neighbor_mem_cap_mb, cfg.precompute_neighbors)

    # é˜¶æ®µ 2ï¼šåŒºåŸŸç”Ÿé•¿
    print("[é˜¶æ®µ] 2/5 åŒºåŸŸç”Ÿé•¿åˆ†å‰²")
    region_labels_points, num_regions, region_mean_normals = region_growing(points, normals, curvature, cfg, tree, neighbors)
    print(f"[ç»“æœ] åŒºåŸŸæ•°é‡ï¼š{num_regions}ï¼Œæœ‰æ•ˆç‚¹æ•°ï¼š{int(np.sum(region_labels_points>=0))} / {len(region_labels_points)}")

    # åŒºåŸŸç»Ÿè®¡ï¼ˆæƒé‡=åŒºåŸŸç‚¹æ•°ï¼›ä¹Ÿå¯æ›¿æ¢ä¸ºåŒºåŸŸé¢ç§¯ï¼‰
    region_sizes, _ = compute_region_stats(points, region_labels_points, num_regions)

    # é˜¶æ®µ 3ï¼šä¿å­˜åŒºåŸŸç»“æœ
    print("[é˜¶æ®µ] 3/5 ä¿å­˜åŒºåŸŸç»“æœ")
    pcd_roi = o3d.geometry.PointCloud()
    pcd_roi.points = o3d.utility.Vector3dVector(points)
    pcd_roi.normals = o3d.utility.Vector3dVector(normals)

    base_dir = in_path.parent
    base_name = in_path.stem
    artifacts = save_region_outputs(base_dir, base_name, pcd_roi, region_labels_points, region_mean_normals, cfg)
    out_dir = Path(artifacts["out_dir"])
    for k, v in artifacts.items():
        print(f"  - {k}: {v}")

    # é˜¶æ®µ 4ï¼šç»“æ„é¢ç»„èšç±» + æå‡è§„åˆ™ + å¯¼å‡º + å¯è§†åŒ–
    if not args.no_cluster_sets and num_regions > 0:
        print("[é˜¶æ®µ] 4/5 ç»“æ„é¢ç»„èšç±»ï¼ˆæ–¹å‘è§’ï¼Œy>0 åŠçƒï¼›ä¸äº§ç”Ÿåˆ†ç»„å™ªå£°ï¼‰")
        try:
            set_labels_regions, K, set_mean_normals, set_kappa, set_sizes, set_weights = cluster_joint_sets(
                region_mean_normals,
                region_sizes,
                total_points=points.shape[0],
                eps_deg=args.sets_eps_deg,
                min_samples=args.sets_min_samples,
                major_singleton_percent=args.major_singleton_percent
            )
            print(f"[ç»“æ„é¢ç»„] ç»„æ•°ï¼š{K}ï¼ˆå…¨éƒ¨åŒºåŸŸå·²å½’ç»„ï¼Œæ—  -1ï¼‰")

            # ä¿å­˜ç»“æ„é¢ç»„ç›¸å…³ç»“æœï¼ˆå§‹ç»ˆå¯¼å‡ºæ¯ç»„ä¸æœªåˆ†ç»„ï¼‰
            set_artifacts = save_joint_sets(out_dir, base_name,
                                            points, normals,
                                            region_labels_points,
                                            region_sizes,
                                            set_labels_regions,
                                            set_mean_normals,
                                            set_kappa)
            for k, v in set_artifacts.items():
                print(f"  - {k}: {v}")

            # ææŠ•å½±å›¾ï¼ˆå¯é€‰ï¼‰
            if args.plot_stereonet:
                png = plot_stereonet_equal_area(out_dir, base_name, region_mean_normals, set_labels_regions)
                if png:
                    print(f"  - stereonet_png: {png}")

            # 3D æ˜¾ç¤ºï¼ˆæŒ‰ç»„ç€è‰²ï¼‰
            if args.show_sets:
                colors_sets = colorize_by_set_id(region_labels_points, set_labels_regions, K)
                pcd_sets = o3d.geometry.PointCloud()
                pcd_sets.points = o3d.utility.Vector3dVector(points)
                pcd_sets.normals = o3d.utility.Vector3dVector(normals)
                pcd_sets.colors = o3d.utility.Vector3dVector(colors_sets)
                o3d.visualization.draw_geometries([pcd_sets], window_name="Joint Sets Result")

        except RuntimeError as e:
            print(f"[æç¤º] è·³è¿‡ç»“æ„é¢ç»„èšç±»ï¼š{e}")

    else:
        print("[ç»“æ„é¢ç»„] å·²ç¦ç”¨ï¼ˆ--no-cluster-setsï¼‰æˆ–æ— æœ‰æ•ˆåŒºåŸŸã€‚")

    # é˜¶æ®µ 5ï¼šå¯è§†åŒ–ï¼ˆæŒ‰åŒºåŸŸæ³•å‘ï¼‰
    if args.show:
        print("[é˜¶æ®µ] 5/5 å¯è§†åŒ–ï¼ˆæŒ‰åŒºåŸŸæ³•å‘ï¼‰")
        colors = colorize_by_region_normal(region_labels_points, region_mean_normals)
        pcd_colored = o3d.geometry.PointCloud()
        pcd_colored.points = o3d.utility.Vector3dVector(points)
        pcd_colored.normals = o3d.utility.Vector3dVector(normals)
        pcd_colored.colors = o3d.utility.Vector3dVector(colors)
        o3d.visualization.draw_geometries([pcd_colored], window_name="Region Growing Result")

    print("\n[å®Œæˆ] å¤„ç†ç»“æŸ ğŸ‰")


if __name__ == "__main__":
    main()
